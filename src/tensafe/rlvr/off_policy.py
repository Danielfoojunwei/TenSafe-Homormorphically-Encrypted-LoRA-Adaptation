"""
RLVR Off-Policy Correction Utilities

Provides importance sampling corrections for stale rollout data,
essential for async training where rollouts may be generated by
an older policy version.

Features:
- Token-level truncated importance sampling (TIS) ratios
- Sequence-level TIS ratios (geometric mean aggregation)
- Outlier token masking (filters extreme importance ratios)
- Sequence masking (drops sequences with high aggregate staleness)
- Staleness-aware weighting for training loss
"""

from __future__ import annotations

import logging
import math
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


@dataclass
class CorrectionResult:
    """Result from off-policy correction."""

    # Per-token weights (importance ratios, possibly clipped)
    token_weights: List[List[float]]
    # Per-sequence weights
    sequence_weights: List[float]
    # Per-sequence mask (True = keep, False = drop)
    sequence_mask: List[bool]
    # Diagnostics
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class OffPolicyConfig:
    """Configuration for off-policy correction."""

    # Token-level TIS clamp bounds
    tis_clip_min: float = 0.1
    tis_clip_max: float = 10.0

    # Sequence-level outlier thresholds
    seq_ratio_max: float = 5.0
    seq_ratio_min: float = 0.2

    # Outlier token masking threshold (z-score)
    outlier_z_threshold: float = 3.0

    # Whether to use geometric mean for sequence-level aggregation
    use_geometric_mean: bool = True

    # Whether to drop outlier sequences entirely
    drop_outlier_sequences: bool = True

    # Staleness weighting decay (exponential)
    staleness_decay: float = 0.95


def compute_token_tis_ratios(
    logprobs: List[List[float]],
    old_logprobs: List[List[float]],
    clip_min: float = 0.1,
    clip_max: float = 10.0,
    masks: Optional[List[List[float]]] = None,
) -> List[List[float]]:
    """
    Compute token-level truncated importance sampling ratios.

    For each token, ratio = exp(log_pi_new - log_pi_old), clamped to
    [clip_min, clip_max] for numerical stability.

    Args:
        logprobs: Current policy log probabilities [batch x seq_len]
        old_logprobs: Old policy log probabilities [batch x seq_len]
        clip_min: Minimum allowed ratio
        clip_max: Maximum allowed ratio
        masks: Optional loss masks [batch x seq_len]

    Returns:
        Clamped importance ratios [batch x seq_len]
    """
    ratios = []
    for seq_idx in range(len(logprobs)):
        seq_ratios = []
        for t in range(len(logprobs[seq_idx])):
            mask_val = masks[seq_idx][t] if masks else 1.0
            if mask_val < 0.5:
                seq_ratios.append(1.0)
                continue

            log_ratio = logprobs[seq_idx][t] - old_logprobs[seq_idx][t]
            ratio = math.exp(min(log_ratio, 20.0))  # Prevent overflow
            ratio = max(clip_min, min(clip_max, ratio))
            seq_ratios.append(ratio)
        ratios.append(seq_ratios)

    return ratios


def compute_sequence_tis_ratios(
    token_ratios: List[List[float]],
    masks: Optional[List[List[float]]] = None,
    use_geometric_mean: bool = True,
) -> List[float]:
    """
    Aggregate token-level IS ratios to sequence-level ratios.

    Uses either geometric mean (exp(mean(log(ratio)))) or arithmetic
    product of token ratios.

    Args:
        token_ratios: Per-token IS ratios [batch x seq_len]
        masks: Optional loss masks [batch x seq_len]
        use_geometric_mean: Whether to use geometric mean aggregation

    Returns:
        Per-sequence IS ratios [batch]
    """
    seq_ratios = []
    for seq_idx in range(len(token_ratios)):
        log_ratios = []
        for t in range(len(token_ratios[seq_idx])):
            mask_val = masks[seq_idx][t] if masks else 1.0
            if mask_val < 0.5:
                continue
            r = token_ratios[seq_idx][t]
            log_ratios.append(math.log(max(r, 1e-10)))

        if not log_ratios:
            seq_ratios.append(1.0)
            continue

        if use_geometric_mean:
            mean_log_ratio = sum(log_ratios) / len(log_ratios)
            seq_ratios.append(math.exp(min(mean_log_ratio, 20.0)))
        else:
            # Product aggregation (can be numerically unstable)
            total_log = sum(log_ratios)
            seq_ratios.append(math.exp(min(total_log, 20.0)))

    return seq_ratios


def mask_outlier_tokens(
    token_ratios: List[List[float]],
    z_threshold: float = 3.0,
    masks: Optional[List[List[float]]] = None,
) -> Tuple[List[List[float]], Dict[str, float]]:
    """
    Mask tokens with extreme importance ratios (outlier detection).

    Computes z-scores of log-ratios across all tokens. Tokens with
    |z-score| > threshold are masked out (ratio set to 1.0).

    Args:
        token_ratios: Per-token IS ratios [batch x seq_len]
        z_threshold: Z-score threshold for outlier detection
        masks: Optional existing masks

    Returns:
        Updated masks and diagnostic metadata
    """
    # Collect all log-ratios for statistics
    all_log_ratios = []
    for seq_idx in range(len(token_ratios)):
        for t in range(len(token_ratios[seq_idx])):
            mask_val = masks[seq_idx][t] if masks else 1.0
            if mask_val >= 0.5:
                all_log_ratios.append(math.log(max(token_ratios[seq_idx][t], 1e-10)))

    if len(all_log_ratios) < 2:
        out_masks = masks if masks else [[1.0] * len(r) for r in token_ratios]
        return out_masks, {"outlier_fraction": 0.0}

    mean_lr = sum(all_log_ratios) / len(all_log_ratios)
    var_lr = sum((lr - mean_lr) ** 2 for lr in all_log_ratios) / len(all_log_ratios)
    std_lr = math.sqrt(var_lr) + 1e-8

    # Create updated masks
    out_masks = []
    total_tokens = 0
    masked_tokens = 0

    for seq_idx in range(len(token_ratios)):
        seq_mask = []
        for t in range(len(token_ratios[seq_idx])):
            orig_mask = masks[seq_idx][t] if masks else 1.0
            if orig_mask < 0.5:
                seq_mask.append(0.0)
                continue

            log_r = math.log(max(token_ratios[seq_idx][t], 1e-10))
            z_score = abs((log_r - mean_lr) / std_lr)

            if z_score > z_threshold:
                seq_mask.append(0.0)
                masked_tokens += 1
            else:
                seq_mask.append(1.0)
            total_tokens += 1

        out_masks.append(seq_mask)

    outlier_frac = masked_tokens / total_tokens if total_tokens > 0 else 0.0
    return out_masks, {"outlier_fraction": outlier_frac, "masked_tokens": masked_tokens}


def mask_outlier_sequences(
    seq_ratios: List[float],
    ratio_min: float = 0.2,
    ratio_max: float = 5.0,
) -> Tuple[List[bool], Dict[str, float]]:
    """
    Mask entire sequences with extreme aggregate IS ratios.

    Args:
        seq_ratios: Per-sequence IS ratios
        ratio_min: Minimum allowed sequence ratio
        ratio_max: Maximum allowed sequence ratio

    Returns:
        Per-sequence mask (True=keep) and diagnostics
    """
    mask = []
    dropped = 0
    for ratio in seq_ratios:
        if ratio < ratio_min or ratio > ratio_max:
            mask.append(False)
            dropped += 1
        else:
            mask.append(True)

    drop_frac = dropped / len(seq_ratios) if seq_ratios else 0.0
    return mask, {"dropped_sequences": dropped, "drop_fraction": drop_frac}


def compute_staleness_weights(
    generation_steps: List[int],
    current_step: int,
    decay: float = 0.95,
) -> List[float]:
    """
    Compute per-sequence weights based on staleness.

    Trajectories generated by older policy versions receive lower weight.

    Args:
        generation_steps: Step at which each trajectory was generated
        current_step: Current training step
        decay: Per-step decay factor

    Returns:
        Per-sequence staleness weights
    """
    weights = []
    for gen_step in generation_steps:
        staleness = max(0, current_step - gen_step)
        weight = decay ** staleness
        weights.append(weight)
    return weights


def apply_off_policy_correction(
    logprobs: List[List[float]],
    old_logprobs: List[List[float]],
    config: Optional[OffPolicyConfig] = None,
    masks: Optional[List[List[float]]] = None,
    generation_steps: Optional[List[int]] = None,
    current_step: int = 0,
) -> CorrectionResult:
    """
    Full off-policy correction pipeline.

    Applies token-level TIS, outlier token masking, sequence-level aggregation,
    sequence masking, and staleness weighting in a single call.

    Args:
        logprobs: Current policy log probabilities [batch x seq_len]
        old_logprobs: Old policy log probabilities [batch x seq_len]
        config: Off-policy correction configuration
        masks: Optional loss masks
        generation_steps: Step at which each trajectory was generated
        current_step: Current training step

    Returns:
        CorrectionResult with all weights and masks
    """
    if config is None:
        config = OffPolicyConfig()

    # Step 1: Token-level TIS ratios
    token_ratios = compute_token_tis_ratios(
        logprobs, old_logprobs,
        clip_min=config.tis_clip_min,
        clip_max=config.tis_clip_max,
        masks=masks,
    )

    # Step 2: Outlier token masking
    updated_masks, token_meta = mask_outlier_tokens(
        token_ratios,
        z_threshold=config.outlier_z_threshold,
        masks=masks,
    )

    # Step 3: Sequence-level aggregation
    seq_ratios = compute_sequence_tis_ratios(
        token_ratios,
        masks=updated_masks,
        use_geometric_mean=config.use_geometric_mean,
    )

    # Step 4: Sequence masking
    if config.drop_outlier_sequences:
        seq_mask, seq_meta = mask_outlier_sequences(
            seq_ratios,
            ratio_min=config.seq_ratio_min,
            ratio_max=config.seq_ratio_max,
        )
    else:
        seq_mask = [True] * len(seq_ratios)
        seq_meta = {"dropped_sequences": 0, "drop_fraction": 0.0}

    # Step 5: Staleness weighting
    if generation_steps is not None:
        staleness_weights = compute_staleness_weights(
            generation_steps, current_step, config.staleness_decay
        )
        # Combine with sequence ratios
        final_seq_weights = [
            sr * sw for sr, sw in zip(seq_ratios, staleness_weights)
        ]
    else:
        final_seq_weights = seq_ratios

    # Combine metadata
    metadata = {
        **token_meta,
        **seq_meta,
        "mean_seq_ratio": (
            sum(seq_ratios) / len(seq_ratios) if seq_ratios else 1.0
        ),
        "mean_seq_weight": (
            sum(final_seq_weights) / len(final_seq_weights)
            if final_seq_weights
            else 1.0
        ),
    }

    return CorrectionResult(
        token_weights=token_ratios,
        sequence_weights=final_seq_weights,
        sequence_mask=seq_mask,
        metadata=metadata,
    )
